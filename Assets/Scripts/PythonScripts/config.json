{
    "model_paths": {
        "MDM": "C:\\Users\\Ciro\\Desktop\\Tesi\\Progetti\\motion-diffusion-model",
        "GMD": "C:\\Users\\Ciro\\Desktop\\Tesi\\Progetti\\guided-motion-diffusion",
        "MoMask": "C:\\Users\\Ciro\\Desktop\\Tesi\\Progetti\\momask-codes",
        "T2M-GPT": "C:\\Users\\Ciro\\Desktop\\Tesi\\Progetti\\T2M-GPT",
        "LADiff": "C:\\Users\\Ciro\\Desktop\\Tesi\\Progetti\\LADiff\\src",
        "SMooDi": "C:\\Users\\Ciro\\Desktop\\Tesi\\Progetti\\SMooDi",
        "AttT2M": "D:\\Tesi\\AttT2M",
        "Gesticulator": "C:\\Users\\Ciro\\Desktop\\Tesi\\Progetti\\gesticulator\\demo"
    },
    "model_commands": {
        "GMD": "conda activate gmd && python -m sample.generate --model_path ./save/unet_adazero_xl_x0_abs_proj10_fp16_clipwd_224/model000500000.pt --output_dir {output_dir} --text_prompt \"{prompt}\" --motion_length {motion_length} && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_1.bvh && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_2.bvh",
        "MDM": "conda activate mdm && python -m sample.generate --model_path ./save/humanml_enc_512_50steps/model000750000.pt --text_prompt \"{prompt}\" --output_dir {output_dir} --motion_length {motion_length} && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_1.bvh && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_2.bvh",
        "T2M-GPT": "conda activate t2mgpt && python generate.py --output_dir {output_dir} --text_prompt \"{prompt}\" && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh",
        "MoMask": "conda activate momask && python gen_t2m.py --gpu_id 0 --ext {output_dir} --text_prompt \"{prompt}\" --iterations {iterations}  --motion_length {motion_length} && move {output_dir}\\animations\\0\\*.bvh {output_dir} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\results.bvh && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\results_ik.bvh",
        "LADiff": "conda activate ladiff && python demo.py --prompt \"{prompt}\" --length {motion_length} --out_dir {output_dir} && conda activate gmd && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh",
        "SMooDi": "conda activate omnicontrol && python demo_cmld.py --cfg ./configs/config_cmld_humanml3d.yaml --guidance_scale_style {gss} --cfg_assets ./configs/assets.yaml --prompt \"{prompt}\" --length {int(motion_length * 20)} --output_dir {output_dir} && conda activate ladiff && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh",
        "AttT2M": "conda activate ladiff && python vis.py --out-dir {output_dir} --prompt \"{prompt}\" && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh"
    },
    "model_commands_noLength": {
        "GMD": "conda activate gmd && python -m sample.generate --model_path ./save/unet_adazero_xl_x0_abs_proj10_fp16_clipwd_224/model000500000.pt --output_dir {output_dir} --text_prompt \"{prompt}\" && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_1.bvh && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_2.bvh",
        "MDM": "conda activate mdm && python -m sample.generate --model_path ./save/humanml_enc_512_50steps/model000750000.pt --text_prompt \"{prompt}\" --output_dir {output_dir} && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_1.bvh && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_2.bvh",
        "T2M-GPT": "conda activate t2mgpt && python generate.py --output_dir {output_dir} --text_prompt \"{prompt}\" && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh",
        "MoMask": "conda activate momask && python gen_t2m.py --gpu_id 0 --ext {output_dir} --text_prompt \"{prompt}\" --iterations {iterations} && move {output_dir}\\animations\\0\\*.bvh {output_dir} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\results.bvh && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\results_ik.bvh",
        "LADiff": "conda activate ladiff && python demo.py --prompt \"{prompt}\" --out_dir {output_dir} && conda activate gmd && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh",
        "SMooDi": "conda activate omnicontrol && python demo_cmld.py --cfg ./configs/config_cmld_humanml3d.yaml --guidance_scale_style {gss} --cfg_assets ./configs/assets.yaml --prompt \"{prompt}\" --length 196 --output_dir {output_dir} && conda activate ladiff && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh", 
        "AttT2M": "conda activate ladiff && python vis.py --out-dir {output_dir} --prompt \"{prompt}\" && python .\\smpl2bvh.py --input_file {output_dir}\\results.npy --output_dir {output_dir} --iterations {iterations} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\anim_0.bvh",
        "Gesticulator": "conda activate gesticulator && python demo.py --audio input/jeremy_howard.wav --text \"{prompt}\" --video_out {output_dir} && conda activate bvh2fbx && python .\\bvh2fbx\\convert_fbx.py -- {output_dir}\\temp.bvh"
    }
}

